[~~# 1.关于jvm内存的模型的复习

在java虚拟机规范的2.5章看

## jdk8的内存模型

1.栈
2.堆(新生代（eden和幸存代）和老年代)
3.程序计数器
4.方法区（就是永久代,jdk8移除了,）
5.字符串常量池
6.本地方法栈
7.堆外（直接内存）

## jdk21的内存模型

1. 寄存器pc，程序计数器
2. 本地方法栈
3. 虚拟机栈
    * 如果 线程中的计算需要比 Java 虚拟机堆栈更大的 Java 虚拟机堆栈 允许，则 Java 虚拟机会抛出 .StackOverflowError

    * 如果 Java 虚拟机堆栈可以动态扩展，扩展是 可以使已尝试但内存不足以生效 扩展，或者如果内存不足，可以用于 为新线程创建初始
      Java 虚拟机堆栈，Java 虚拟机会抛出OutOfMemoryError
4. 堆
5. 方法区
    * 如果 方法区域中的内存无法用于满足 分配请求时，Java 虚拟机会抛出 .OutOfMemoryError
6. 运行时常量池
    * 什么时候 创建一个类或接口，如果运行时的构造 常量池需要的内存多于 Java 虚拟机的方法区域，Java 虚拟机抛出一个
      .OutOfMemoryError

# 2.oom发生的几种可能

1.分配一个超大对象，类似一个超大数组超过堆的最大值会oom
2.堆内存不足导致oom，xmx调节堆大小
3.程序不断递归调用，不停压栈会抛出stackoverflow,如果jvm这时候去扩展栈空间且失败就会抛出oom
4.老版本永久带因为大小有限也会经常oom比如intern字符串缓存过多。
5.直接内存不足也会oom

# 3.初始化一个类的步骤

1. 分配对象内存空间
2. 初始化对象
3. 设置instance指向刚刚分配的内存地址, 此时instance != null (重点)

由于第二步和第三步没有依赖关系所以可能会被重排优化

1. 分配对象内存空间
2. 设置instance指向刚刚分配的内存地址, 此时instance != null (重点)
3. 初始化对象

原子性一般是说读写等操作是不可分割的

可见性是多线程情况下对工作内存的变量修改会同步到主内存，多线程可见

有序性就是代码按照顺序执行不会被指令重排

# 4.happens-before原则

1. 一个线程内代码循序执行(单线程内指令重排序不会影响代码顺序执行)

2. unlock操作现行发生于同一个锁的lock，也就是说第二次上锁，需要先解锁

3. 对于volatile写操作先行于读操作

4. 对与线程来说start()优先于其他动作

5. 线程的其他动作又优先于线程终止规则

6. 线程的中断调用interrupt()优先于中断检测interrupted()

7. 一个对象的构造函数执行优先于finalize()方法

8.a操作先行于b操作，b操作先行于c操作，所以a先行于c

无锁都是基于硬件的原子操作实现的

cas会有aba问题就是要被赋值的变量在检测的时候，由a变成了b又变回了a这样就会通过检测，java是靠版本号（对变量维护一个版本号）来优化解决这个问题的

自旋避免了线程切换的开销，但是占用了处理器时间

# 5.关于锁

1.关于Synchronized

    1.使用
    修饰实例方法，对当前实例对象this加锁
    修饰静态方法，对当前类的class对象加锁
    修饰代码块，制定一个加锁的对象，给对象加锁

    2.对象组成

        对象头
        mark word字段：存储对象的hashcode,存储分代年龄，存储锁标志位信息
        （00轻量级锁01无锁或者偏向锁10重锁11垃圾回收标记）

        klass point: 对象指向它的类元数据的指针，虚拟机通过这指针判断这对象是哪个类的实例

        实例数据
        存放类的数据信息，父类的信息

        填充数据
        虚拟机要求对象的起始地址必须是8字节的整数倍，为了字节对齐
        空对象的大小就是8字节，因为会自动对齐

    3.可重入性

        Synchronized锁对象的时候有个计数器，会记录下线程获取锁的次数，在执行完对应的代码块之后，计数器就会-1
        直到计数器清零，就释放锁了。

    4.不可中断性
    
        就是说，一个线程获取锁之后，另一个线程处于阻塞或者等待状态，前一个不释放，后一个也已知会阻塞或者等待，不可以被中断

    5.javap -c xxx.class可以查看反编译文件
    首先关联到一个monitor对象。
    当我们进入一个方法的时候，执行monitorenter，就会获取当前对象的一个所有权，这个时候monitor进入数为1，当前的这个线程就是这个monitor的owner。
    如果你已经是这个monitor的owner了，你再次进入，就会把进入数+1.
    同理，当他执行完monitorexit，对应的进入数就-1，直到为0，才可以被其他线程持有。
    不知道大家注意到方法那的一个特殊标志位没，ACC_SYNCHRONIZED。
    同步方法的时候，一旦执行到这个方法，就会先判断是否有标志位，然后，ACC_SYNCHRONIZED会去隐式调用刚才的两个指令：monitorenter和monitorexit。
    所以归根究底，还是monitor对象的争夺。

    6.无锁->偏向锁->轻锁->重锁（锁升级过程）

    为什么需要有锁升级这种优化？
    多线程在同一时刻请求同一把锁，没拿到锁的线程需要被阻塞，所以需要用重量级锁（重锁有自旋，取消，粗化等优化）
    多线程在不同时间段请求同一把锁，也就是说没有锁竞争需要轻量级锁
    锁一直被同一个线程所持有，使用偏向锁即可

    synchronized四种写法嘛
    1.显式锁对象
    2.锁方法
    这两种是锁的实例化的对象
    3.锁static方法
    4.锁代码块
    是锁的类.class这个对象

## wait()和sleep()的区别

wait()来自Object类，sleep()来自Thread类

1. 是否释放锁？
   调用 sleep()方法，线程不会释放对象锁。而调用 wait() 方法线程会释放对象锁；
2. 是否释放cpu
   sleep()释放cpu，wait()释放 CPU；
3. 是否中断敏感
   sleep()是，wait()是.

# 6.类加载的过程

1.加载 2.链接 3.初始化

1.字节码被读取到jvm中映射为class对象
2.链接分为三个过程：
1.验证：验证字节信息是否符合jvm规范
2.准备：申请静态变量需要的内存，但不执行赋值操作
3.解析：将常量池中的符号引用变成直接引用
3.真正执行类的初始化代码，包括静态变量的赋值，静态初始化块内的逻辑

什么叫做双亲委派模型
1.就是一个类被加载的时候先找父类加载器，再找当前加载器
2.类加载器分为bootstrap（.jar）,ext(/jre/lib),app(classpath),自定义加载器

# 7.逃逸分析的判断

一是对象是否被存入堆中（静态字段或者堆中对象的实例字段），二是对象是否被传入未知代码中。

一旦对象被存入堆中，其他线程便能获得该对象的引用。即时编译器也因此无法追踪所有使用该对象的代码位置。

由于 Java 虚拟机的即时编译器是以方法为单位的，对于方法中未被内联的方法调用，即时编译器会将其当成未知代码，毕竟它无法确认该方法调用会不会将调用者或所传入的参数存储至堆中。因此，我们可以认为方法调用的调用者以及参数是逃逸的

如果即时编译器能够证明锁对象不逃逸，那么对该锁对象的加锁、解锁操作没有意义。这是因为其他线程并不能获得该锁对象，因此也不可能对其进行加锁。在这种情况下，即时编译器可以消除对该不逃逸锁对象的加锁、解锁操作。就是你说的锁消除

如果逃逸分析能够证明某些新建的对象不逃逸，那么 Java 虚拟机完全可以将其分配至栈上，并且在 new
语句所在的方法退出时，通过弹出当前方法的栈桢来自动回收所分配的内存空间。这样一来，我们便无须借助垃圾回收器来处理不再被引用的对象

但是java没有使用栈上分配

而是使用了标量替换

那什么是标量替换呢？

就是将原本对对象的字段的访问，替换为一个个局部变量的访问

这些字段既可以存储在栈上，也可以直接存储在寄存器中。而该对象的对象头信息则直接消失了，不再被保存至内存之中。

由于该对象没有被实际分配，因此和栈上分配一样，它同样可以减轻垃圾回收的压力。与栈上分配相比，它对字段的内存连续性不做要求，而且，这些字段甚至可以直接在寄存器中维护，无须浪费任何内存空间。

# 8.关于wait()和notify()用法

notify()一定要写在wait()的前面,这样才能及时唤醒

wait 必须放在同步块，或者同步方法中。而sleep可以任意位置

# 9.关于数据库的水平拆分和垂直拆分

举个栗子
user{
id
name
age
}

我们把user存在不同的user表里面，每个user具体去那个表可以做个hash,实际就是我们一个user表拆分成了多个user表。这就是水平拆分

特点

每个表结构的都一样
每个表数据都不一样，没有交集
每个表都不是全量数据

2.什么是垂直拆分？

一行的数据如果太大，那就分成，多张表，表与表之间用某一列数据做连接（一般是主键）

特点

每个表数据都不一样，但有交集
每个表结构都不一样
每个表都不是全量数据

什么是mysql的预读
其实这不只是mysql，而是说一次最少读一个内存页（一页4k）,这样也许会多读，但是把下一次可能用到的的数据也读到了，减少了磁盘io

mysql的锁结构其实就是个内存结构

重要的两个字段

trx:代表当前锁是哪个事务生成的

is_waiting：代表当前事务是否在等待

# 10.关于2pc

1.第一阶段投票阶段

参与者通知协调者，协调者反馈结果

2.第二个阶段

收到参与者的反馈后，协调者再向参与者发出通知，根据反馈情况决定各参与者是否提交还是回滚

# 11.关于二叉树

1.高度和深度都是从0开始的,层数从1开始

2.满二叉可以利用数组存储，为了方便计算节点一般从下标为1开始存储

3.树的前中后遍历其实是对于根节点的前中后
前：根左右
中：左根右
后：左右根

4.迭代写法无非是起一个栈把节点存进去while循环不断迭代按照根左右的顺序输出

5.dfs深度遍历分为前中后序三种
bfs宽度优先搜索

# 12.二叉查找树

1.先说要求
二叉查找树的要求,在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点，右子树的每个节点都要大于这个节点。

2.查找,遍历,删除相关的操作

# 13.copy-on-write

本质是一种延时策略，只有在真正需要的时候才复制，而不是提前复制好。

适合场景:读多写少，弱一致性。

没有提供CopyOnWriteLinkedList是因为linkedlist的数据结构关系分散到每一个节点里面，对每一个节点的修改都存在竟态条件，需要同步才能保证一致性。arraylist就不一样，数组天然的拥有前驱后继的结构关系，对列表的增删，因为是copy
on
wirte，所以只需要cas操作数组对象就能够保证线程安全，效率上也能接受，更重要的是避免锁竞争带来的上下文切换消耗。有一点需要注意的是CopyOnWriteArrayList在使用上有数据不完整的时间窗口，要不要考虑需要根据具体场景定夺

## 设计一个rpc的路由表

思考

1.每次 RPC 调用都需要访问路由表，所以访问路由表这个操作的性能要求是很高的。

2.不过路由表对数据的一致性要求并不高，一个服务提供方从上线到反馈到客户端的路由表里，即便有 5
秒钟，很多时候也都是能接受的（这个时间参考了注册中心nacos）

3.路由表是典型的读多写少类问题

综合：对读的性能要求很高，读多写少，弱一致性。

设计

服务提供方的每一次上线、下线都会更新路由信息。
1.一种是通过更新 Router 的一个状态位来标识，如果这样做，那么所有访问该状态位的地方都需要同步访问，这样很影响性能。

2.另外一种就是采用 Immutability 模式，每次上线、下线都创建新的 Router 对象或者删除对应的 Router
对象。由于上线、下线的频率很低，所以后者是最好的选择。

结果

1.选择第二种方式来实现 使用copy-on-write

大概结构ConcurrentHashMap<String, CopyOnWriteArraySet<Router>>

路由表就是一个namenode

# 14.关于一次加载和懒加载

1.一次加载顾名思义就是一次把需要的数据在初始化的时候一次性全查出来加入缓存。

2.懒加载需要哪一个数据就加载那个数据，不会多加载

# 15.关于代码级别的锁升级与降级

1.获取读锁，在没有释放读锁的情况下获取写锁，典型的锁升级场景，java不允许这样。
此时读锁还没有释放。

2.获取写锁，获取读锁，释放读锁，释放写锁。典型的锁降级场景

# 16关于wait()和await()的关系

线程等待和通知需要调用 await()、signal()、signalAll()，它们的语义和 wait()、notify()、notifyAll() 是相同的。但是不一样的是，Lock&Condition
实现的管程里只能使用前面的
await()、signal()、signalAll()，而后面的 wait()、notify()、notifyAll() 只有在 synchronized 实现的管程里才能使用。如果一不小心在
Lock&Condition
实现的管程里调用了 wait()、notify()、notifyAll()，那程序可就彻底玩儿完了。

# 17.关于线程池

1.初始化
ThreadPoolExecutor(
int corePoolSize,//保持的最小线程数
int maximumPoolSize,//最大线程数
long keepAliveTime,//当线程空闲这么长时间后,且线程数大于corePoolSize，就要回收多余的线程资源
TimeUnit unit,
BlockingQueue<Runnable> workQueue,//工作队列
ThreadFactory threadFactory,//线程工厂，自定义如何创建线程
RejectedExecutionHandler handler//拒绝策略
如果线程池中所有的线程都在忙碌，并且工作队列也满了（前提是工作队列是有界队列），那么此时提交任务，线程池就会拒绝接收。
)
2.四种拒绝策略
1.CallerRunsPolicy：提交任务的线程自己去执行该任务。
2.AbortPolicy：默认的拒绝策略，会 throws RejectedExecutionException。
3.DiscardPolicy：直接丢弃任务，没有任何异常抛出。
4.DiscardOldestPolicy：丢弃最老的任务，其实就是把最早进入工作队列的任务丢弃，然后把新任务加入到工作队列。

# 18.mysql方案的一些问题.

1.执行计划是单机的
2.如果一张表分布在不同的mysql server中那么读取下一行可能会很大
3.数据复制问题,mysql是半同步或者异步的

# 19.关于ioc

1.什么是控制反转
控制反转就是把创建bean的过程移交给第三方，这个第三方就是容器container

    容器负责创建、配置和管理 bean，也就是它管理着 bean 的生命，控制着 bean 的依赖注入。

    通俗点讲，因为项目中每次创建对象是很麻烦的，所以我们使用 Spring IoC 容器来管理这些对象，需要的时候你就直接用，不用管它是怎么来的、什么时候要销毁，只管用就好了。

2.什么是bean？

    bean就是包装好的object

3,spring是如何设计容器的？

    使用 ApplicationContext，它是 BeanFactory 的子类，更好的补充并实现了 BeanFactory 的。

    BeanFactory 简单粗暴，可以理解为 HashMap:
    k为全类名 v是对象
    Key - bean name
    Value - bean object

4.ApplicationContext 的里面有两个具体的实现子类，用来读取配置配件的：

    ClassPathXmlApplicationContext - 从 class path 中加载配置文件，更常用一些；
    FileSystemXmlApplicationContext - 从本地文件中加载配置文件，不是很常用，如果再到 Linux 环境中，还要改路径，不是很方便。

其实这就是 IoC 给属性赋值的实现方法，我们把「创建对象的过程」转移给了 set() 方法，而不是靠自己去 new，就不是自己创建的了。

这里我所说的“自己创建”，指的是直接在对象内部来 new，是程序主动创建对象的正向的过程；这里使用 set() 方法，是别人（test）给我的；而
IoC 是用它的容器来创建、管理这些对象的，其实也是用的这个 set()
方法，不信，你把这个这个方法去掉或者改个名字试试？

何为控制，控制的是什么？

答：是 bean 的创建、管理的权利，控制 bean 的整个生命周期。

何为反转，反转了什么？

答：把这个权利交给了 Spring 容器，而不是自己去控制，就是反转。由之前的自己主动创建对象，变成现在被动接收别人给我们的对象的过程，这就是反转。

何为依赖，依赖什么？

程序运行需要依赖外部的资源，提供程序内对象的所需要的数据、资源。

何为注入，注入什么？

配置文件把资源从外部注入到内部，容器加载了外部的文件、对象、数据，然后把这些资源注入给程序内的对象，维护了程序内外对象之间的依赖关系。

所以说，控制反转是通过依赖注入实现的。但是你品，你细品，它们是有差别的，像是「从不同角度描述的同一件事」：

IoC 是设计思想，DI 是具体的实现方式；
IoC 是理论，DI 是实践；
从而实现对象之间的解藕(这样你们不管怎么修改外部的对象，都对我们内部的对象没有影响)。

当然，IoC 也可以通过其他的方式来实现，而 DI 只是 Spring 的选择。

IoC 和 DI 也并非 Spring 框架提出来的，Spring 只是应用了这个设计思想和理念到自己的框架里去。

# 20.关于网络的七层模型

1.物理层面
2.链路层
3.网络层
4.传输层(tcp/udp)
5.会话层
6.表示层
7.应用层

## 什么是tcp?

TCP 是面向连接的、可靠的、基于字节流的传输层通信协议。

## 什么是一个tcp连接呢？

用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。

Socket：由 IP 地址和端口号组成

序列号(sequence numbers)：用来解决乱序问题等

窗口大小(window size)：用来做流量控制

## 滑动窗口

上面所说的窗口大小就是滑动窗口，原理如下

* 发送方和接收方各自维护一个窗口。发送方的窗口叫做发送窗口，接收方的窗口叫做接收窗口。窗口的大小是动态调整的，可以根据网络的拥塞程度和接收方的处理能力进行调整。
* 发送窗口内的数据包是可以被发送出去的，而接收窗口内的数据包是可以被接收的。发送窗口和接收窗口的大小决定了发送方一次可以发送多少数据，以及接收方一次可以接收多少数据。
*

当发送方发送数据包后，会启动一个定时器，等待接收方的确认。如果在定时器到期之前接收到了确认，那么发送方会将窗口向前滑动，将已经被确认的数据包从窗口中移除，并将新的数据包加入到窗口中。如果在定时器到期之前没有接收到确认，那么发送方会认为数据包丢失，然后重新发送数据包，并将窗口的大小减小，以减少网络的拥塞。

* 接收方在接收到数据包后，会发送确认给发送方，并将窗口向前滑动，将已经被确认的数据包从窗口中移除，并将新的数据包加入到窗口中。如果接收方发现自己处理不过来，可以通过减小接收窗口的大小，告诉发送方减慢发送速度。

## 如何确定一个唯一的连接呢？

源地址 源端口 目标地址 目标端口（从哪来到哪去）从哪个主机发送到那个主机，从哪个进程发送到那个进程

## 拥塞控制、流量控制

TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。

UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

## 前两次握手不能携带数据，第三次握手可以携带数据

## 为什么一定要三次握手

1.三次握手才可以阻止历史重复连接的初始化（主要原因）
比如旧的syn比新的先到

2.三次握手才可以同步双方的初始序列号
这样一来一回，才能确保双方的初始序列号能被可靠的同步。

3.三次握手才可以避免资源浪费
如果不回复ack，每次syn就要主动建立连接，如果客户端的syn在网络中拥堵了，且收不到ack。就会多次发送syn。这样的话就会建立多个连接，造成连接资源的浪费。

## 何为syn攻击？

在三次握手阶段客户端发送syn服务端发送ack+syn后，客户端不回复ack这样服务端就会一直等待客户端ack直到超时，服务端的syn队列会很快排满

1.修改内核参数
修改队列大小，以及队列满后的处理策略

## 四次挥手（断开连接）

主动关闭连接的，才有 TIME_WAIT 状态。

客户端收到服务端的第三次fin，就会恢复ack，也就是第四次回收，此时客户端连接
进入time_wait状态，等待2msl后才会关闭连接。这个期间如果服务端没有收到ack
就重试发送fin，如果客户端在2msl内收到了新的fin就会重置定时器再等待2msl。

### 为什么需要time_wait

为了保证服务端一定能收到ack，因为网络是不可靠的，可能ack丢失了，如果客户端在2msl内收到了新的fin就会重置定时器再等待2msl。   
防止历史连接中的数据，被后面相同的四元组连接错误的接收。

客户端发起挥手time_wait过多，会导致客户端无法再连接目标服务器

* 解决方案：

1. 强制使用rst关闭连接
2. 内核参数开启后，复用处于 TIME_WAIT 的 socket 为新的连接所用。
   net.ipv4.tcp_tw_reuse = 1
   net.ipv4.tcp_tw_reuse = 1

## http相关

### http1.0

# 21.关于cas

1.本质
是cpu提供了compare and swap指令，该指令提供了三个参数
1.共享变量的内存地址A。
2.用于比较的值B。
3.用于共享变量的新值C。
当A=B时，更新A=C

## ABA

解决方式版本号or时间戳

# 22.关于hashmap的一切

## put

变量初始化：
tab：指向 HashMap 内部数组（Node 数组）的引用。
p：当前处理节点的引用，初始时为 null。
n 和 i：分别表示数组长度和要插入元素的索引位置。
检查并初始化内部数组： 如果 table 为空或者长度为 0，则调用 resize() 方法创建一个新的内部数组，并将 n 设置为新数组的长度。
查找插入位置： 使用 (n - 1) & hash 计算出键值对应该存储在数组中的索引 i。如果在该索引位置上的节点 p 为空，则直接新建一个
Node 对象并插入到该位置。
处理已有键值对：
如果在 i 索引处已经有节点 p，且其哈希码与传入的哈希码相同，并且键相等，则找到已存在的键值对，赋给 e。
如果 p 是一颗红黑树（TreeNode）的节点，则通过 putTreeVal() 在红黑树中插入或更新键值对。
否则，遍历链表直到找到匹配的键值对（或链表末尾），找到后停止遍历。
更新键值对：
如果找到了已存在的键值对（即 e != null），根据 onlyIfAbsent 参数决定是否替换旧值。如果 onlyIfAbsent 为 false 或者旧值为
null，则将新值覆盖旧值，并返回旧值。
调用 afterNodeAccess(e) 方法执行后续操作（例如，统计访问次数等，但在默认 HashMap 实现中这个方法是空的）。
更新修改相关计数器：
增加 modCount（修改次数）以跟踪结构修改。
更新容器大小 size，并在超过阈值 threshold 时调用 resize() 进行扩容。
插入新键值对： 如果没有找到已存在的键值对，则在链表末尾插入新的键值对，并调用 afterNodeInsertion(evict)
方法（在默认实现中用于可能的驱逐操作，如 LRU 缓存策略下的驱逐）。

## get

初始化变量：
tab：指向 HashMap 内部数组（Node 数组）的引用。
first 和 e：分别表示链表的第一个节点和遍历过程中的当前节点。
n 和 hash：分别表示数组长度和要查找的键的哈希码。
k：临时存储键对象的引用。
检查条件：
确保哈希表不为空 (table != null)，并且其长度大于 0 (n > 0)。
根据传入的 key 计算哈希码，并使用这个哈希码定位到数组索引位置上的第一个节点 first。
判断第一个节点是否匹配：
如果第一个节点的哈希码与目标哈希码相同，并且键也相等（或经过 equals() 方法判断为相等），则直接返回第一个节点。
遍历链表：
如果第一个节点后面还有其他节点（即 first.next != null），则继续检查后续节点。
如果第一个节点是一个树节点（TreeNode，意味着已经转换为了红黑树结构），则调用 getTreeNode(hash, key) 在红黑树中查找对应节点并返回。
否则，通过循环遍历链表，逐个检查节点的哈希码和键是否与目标一致，如果找到匹配的节点，则返回该节点。
若未找到匹配的节点，则返回 null。

## 1.组成

是有数组和链表组成的，根据hash求出数组索引
。当索引重复的时候新的键值对就会在链表上增加一个节点(Node<k,v>)

## 2.当hash重复的时候是如何插入的呢？

1.8之前是头插法（就是插在链表的头部）
1.8之后是尾插法

为什么会修改呢？
因为头插法会在多线程插入且rehash的时候形成循环链表
尾插法不会修改链表的顺序所以不会引发这个问题

## 3.为何resize,何时resize

1.当容量不够的时候需要扩容，就需要resize了
2.当存储的键值对达到容量*0.75(负载因子)就需要resize

## 如何扩容

1.创建一个长度是原数组两倍的新数组(oldThr << 1 左移相当于*2).
2.遍历原数组，把所有键值对重新hash到新数组里面

## 如何计算hash值

hash=key.hashcode() ^ (key.hashcode()>>>16)
1.为什么选择^(异或)
1,1
0,1
1,0
0,0
或:(有一个1就为真所以75%为1).
与:(有两个1才为真所以75%为0).
异或:(操作位相同为真所以0,1几率都为50%).
从数字重复几率的角度选择操作符为^.
右移16位相当与保留了高16的信息(从低到高从右到左)

## 为什么rehash

1.求index的公式index =hash（Key） & （Length - 1）
当数组长度不一致时(也就是扩容的时候)计算出来的值也变了。

## 为什么是默认初始化容量是16

因为16-1是15，15的二进制是1111
可以的hashcode&1111得出的十进制数就是4，只要length-1不是2的幂数，那么转二进制之后，
就都是1，那么hash算法算出的数字就和hashcode的后几位有关。那么只要hashcode均匀那么hash
算法就是均匀的

## 为什么重写equals需要重写hashcode?

因为equals是比较两个内存的地址，如果是值对象就比较两个对象的值
如果是引用对象，就比较两个引用的地址。
如果我们的两个对象算出的index都是2那么他们就存在同一个链表里面了
如果他们hashcode一致我没就没法区分到底我们想要get的是哪个。
所以我们需要重写hashcode算法.保证每一个key的hashcode都不一样

## 插入过程

1.链表法：先key hash func获取存在那个桶里(数组)然后用index公式获取插在数组的那个位置，如果当前数组的位置已经有内容了
就使用尾插法插入链表。
2.开放地址法：当前桶被占了，就用一定的方式去找下一个桶，直到找到空的

## 什么时候转红黑树

当链表大小超过8个的时候。

## 与hashtable的对比

1.hashtable是并发安全的，hashmap不是，所以在多线程写入的时候会有数据覆盖问题。hashtable不允许键值为null，hashmap允许
hashmap：
初始化容量是16
扩容直接乘2

hashtable：
初始化容量是11
乘2+1

## fail-fast机制是怎么回事？

快速失败是java集合中的一种机制，在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容做了修改，就会抛出异常。集合会维护一个modcount变量，执行一个hashNext()
/Next()
的时候会去判断modcount是否为expectedmodCount，如果不是就抛出异常

## fail-safe

安全失败是并发包里面的机制，即查询的时候先看数据存在不存在

# 23.ConcurrentHashMap

使用了分段锁，锁的是数组的每一个元素。

默认容量是16

## 插入

1.先是尝试获取锁
2.自旋获取锁(scanAndLockForPut(key,hash,value))
3.自旋到一定次数，改为阻塞获取锁
4.put的时候会判断value==null如果等于会抛出异常

也就是说一定是获取锁再去操作

步骤和之前的hashmap一样，先算出index
然后遍历链表，如果有hashcode相等的就说明
当前节点存在，那么需要更新节点，如果当前节点不存在，
那么就new一个新节点，然后将新节点利用尾插法插入链表
修改成之后释放锁。

jdk 1.7使用的是segment分段锁

jdk 1.8使用cas+synchronize

之前的方式是获取锁然后写入，现在是先cas写入，如果容量不足则需要扩容。
如果都不满足怎利用synchronized锁写入数据
如果链表大于8个节点了，需要转成红黑树

# 24.回顾缓存行

1.为什么要有缓存行？
因为cpu比内存快太多了，为了更快的从内存中读取数据，于是诞生了多级缓存

2.查询过程
首先会去L1缓存查找所需数据，如果没找到，再去L2缓存查找，一次类推，知道从内存中获取数据，这也就意味着，越长的调用链，所耗费的时就越长，如果每次去主存的时候多拿一些，那么是不是就避免了频繁您访问主存了呢？一般来说每个缓存行大小为64字节，并且每个缓存行有效的引用主内存的一块儿地址，cpu每次从主内存中获取数据时，会将相邻的数据也一同拉取到缓存行中，这样当cpu执行运算时，就大大减少了于主内存的交互。

3.当多线程同时修改cache会怎么样？
core1上的线程修改了l1里面的a，同时告诉其他cpul1里面的缓存引用已经没用了，这时core2上的线程发起了修改同一个缓存中的变量b，为了可见性core会将数据回写回主存。此时core2将内存重新读取到l1缓存然后在修改。所以说一个cache
line的数据被多线程访问，就会相互竞争，并且频繁回写。

4.那么如何解决未共享问题？
数据填充，填满一个缓存行。即当前数据和填充数据的大小为64字节，下一个数据放在下一个64字节里面即可。

# 25.随便复习一下快速排序

1.第一步选择一个基准值，一般选择头部元素作为基准值
2.将小于基准值的元素放在基准值的前面，将大于基准值的元素放在基准值后面。

# 26.jdk动态代理和cglib的区别

JDK 动态代理只能只能代理实现了接口的类，而 CGLIB 可以代理未实现任何接口的类。 另外， CGLIB
动态代理是通过生成一个被代理类的子类来拦截被代理类的方法调用，因此不能代理声明为 final
类型的类和方法。就二者的效率来说，大部分情况都是 JDK 动态代理更优秀，随着 JDK 版本的升级，这个优势更加明显。

# 27.关于ThreadLocal

# 28缓存更新的套路

## 1.Cache Aside Pattern

失效:应用程序先从cache取数据，没有得到，则从数据库读取，成功后放到缓存中。
命中:应用程序从cache中取数据，取到后返回
更新:先把数据存到数据库中，成功后，再让缓存失效。
一个读操作没有命中缓存，然后就去数据库拉数据了，同时有一个并发写操作，写完数据库之后让缓存失效，然后之前的读操作会把老数据放入缓存，所以，会造成脏数据。

## 2.Read/Write Through Pattern

更新数据库的操作由缓存代理，从应用来说后端就是一个单一的存储。

Read Through
如果读的时候缓存失效，缓存服务将数据从数据库读出并加入缓存。

Write Through
当有数据更新且没有命中缓存，就直接更新数据库。命中了就先更新缓存，再更新数据库

## 3.Write Behind Caching Pattern

更新数据的时候只更新缓存，不更新数据库，由缓存异步批量的更新数据库

操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy
write。

## 补充

1. 想要提高应用的性能，可以引入「缓存」来解决
2. 引入缓存后，需要考虑缓存和数据库一致性问题，可选的方案有：「更新数据库 + 更新缓存」、「更新数据库 + 删除缓存」
3. 更新数据库 + 更新缓存方案，在「并发」场景下无法保证缓存和数据一致性，且存在「缓存资源浪费」和「机器性能浪费」的情况发生
4. 在更新数据库 + 删除缓存的方案中，「先删除缓存，再更新数据库」在「并发」场景下依旧有数据不一致问题，解决方案是「延迟双删」，但这个延迟时间很难评估，所以推荐用「先更新数据库，再删除缓存」的方案
5. 在「先更新数据库，再删除缓存」方案下，为了保证两步都成功执行，需配合「消息队列」或「订阅变更日志」的方案来做，本质是通过「重试」的方式保证数据一致性
6. 在「先更新数据库，再删除缓存」方案下，「读写分离 +
   主从库延迟」也会导致缓存和数据库不一致，缓解此问题的方案是「延迟双删」，凭借经验发送「延迟消息」到队列中，延迟删除缓存，同时也要控制主从库延迟，尽可能降低不一致发生的概率

# 29.关于LRU

最近最少使用。假设最少使用的信息，将来被使用的概率也不大，所以在内存不够的情况下，就可以吧这些不常用的信息踢出去，腾地方。

FIFO先进先出

LFU 对每个访问信息记数，踢走访问次数最的那个，如果访问次数一样，就踢走好久没用过的那个。

# 30.堆和堆排序

1.堆是一个完全二叉树

2.完全二叉树就是除最后一层节点，其他层的节点都是满的，最后一层的节点都靠左排序

3.堆中的每个节点的值必须大于等于（或者小于等于）其子树中每个节点的值。实际上，我们还可以换一种说法，堆中每个节点的值都大于等于（或者小于等于）其左右子节点的值。这两种表述是等价的。

4.对于每个节点的值都大于等于子树中每个节点值的堆，我们叫做“大顶堆”。对于每个节点的值都小于等于子树中每个节点值的堆，我们叫做“小顶堆”。

5.因为是完全二叉树，所以适合存储在数组里。如果一个节点为下标i，那么左节点为i*2,右节点为
i*2+1，如果有父节点那父节点为i/2\x32

## 1.添加一个节点

直接将数据放在堆尾，然后开始判断有没有父节点即i/2>0。

然后判断父节点于子节点的大小

大顶堆a[i]>a[i/2]

小顶堆a[i]<a[i/2]

以上这两个条件符合说明需要堆化，即交换元素位置，并继续判断

## 2.删除一个节点

为了让删除后的节点也是一个完全二叉树

例子从根节点开始删除

首先将根节点个尾节点作交换，然后对交换后树进行堆化即可。

# 31.关于redis分布式锁的问题

## 1.上锁

set命令要用set key value px milliseconds nx
jedis.set(String key, String value, String nxxx, String expx, int time)
需要5个参数为了解决四个问题

1.**互斥性。**在任意时刻，只有一个客户端能持有锁。

2.**不会发生死锁。**即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。

3.**具有容错性。**只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。d

4.**解铃还须系铃人。**加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。

第一个为key，我们使用key来当锁，因为key是唯一的。

第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？
原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，
我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。

第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作；

第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。

第五个为time，与第四个参数相呼应，代表key的过期时间。

## 2.解锁

String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end";
Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId));
if (RELEASE_SUCCESS.equals(result)) {
return true;
}

首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）

使用eval()可以保证原子性

## 3.缺陷

如果我们在master节点获取了锁，且锁还没有没有被同步到slave节点，此时如果master节点出现错误，slave节点升级为master节点就会导致锁丢失

## 4.red-lock(3,5,7奇数节点)

1.获取当前Unix时间，以毫秒为单位。

2.依次尝试从5个实例，使用相同的key和具有唯一性的value（例如UUID）获取锁。
当向Redis请求获取锁时，客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。
例如你的锁自动失效时间为10秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。
如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。

3.客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。
当且仅当从大多数（N/2+1，这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。

4.如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。
如果因为某些原因，获取锁失败（没有在至少N/2+1个Redis实例取到锁或者取锁时间已经超过了有效时间）
，客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功，
防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。

# 32.nio

## nio是如何减少数据复制次数的

### 首先说bio模型的四次复制

1. socket到stream缓冲区
2. inputStream到具体对象(比如string)
3. 处理过的对象到outputStream
4. outputStream到socket

### 再说nio两次copy

1. socket到Direct Buffer:数据可以直接从内核缓冲区复制到直接缓冲区中
2. 直接缓冲区的复用:应用程序可以直接对直接缓冲区进行读写操作，不再需要额外的内存复制。
   当数据需要在网络间传输时，直接缓冲区的内容可以直接被写回内核缓冲区，从而减少了不必要的内存复制环节。

* NIO通过直接缓冲区的使用以及更高效的内存管理机制，至少减少了两次以上的数据复制（从内核缓冲区到Java堆内存，以及从Java堆内存到内核缓冲区的复制）

## 零拷贝

### mmap

数据拷贝次数：在理想情况下，mmap可以实现零次数据拷贝，但在某些条件下，仍有可能有一次数据拷贝（例如，当数据需要在用户空间进行处理后再发送时）。
作用：mmap允许将磁盘文件映射到进程的虚拟地址空间，使得进程可以直接访问文件内容，如同访问内存一样。当需要将文件内容发送到网络时，如果文件数据能够直接从mmap映射区域传送到socket缓冲区（利用DMA直接从磁盘到网络接口卡），就可以避免数据在内核缓冲区和用户缓冲区间的拷贝。

### sendfile

数据拷贝次数：sendfile在理想的零拷贝场景下可以实现仅一次数据拷贝（从磁盘到内核态的socket缓冲区）。
作用：sendfile系统调用专门用于在网络传输中直接传递磁盘上的文件数据，它能够在内核态直接将文件缓存中的数据传递到socket缓冲区中，之后再通过DMA传输到网卡，从而避免了数据在用户态和内核态之间的多次拷贝。
sendfile系统调用可以将文件系统缓冲区（page cache）中的数据直接发送到网卡缓冲区，而不需要经过用户空间的缓冲区

kafka就是这样实现的。

### sendmsg (带有SCM_RIGHTS标志)

数据拷贝次数：在某些特殊场景下，如Unix域套接字（Unix Domain Socket,
UDS）的文件描述符传递时，sendmsg可以实现零拷贝，此时文件描述符（而不是文件数据）被直接传递，而不是通过数据拷贝的方式。
作用：sendmsg通常用于发送带附加信息（如文件描述符、地址元数据等）的数据报文。在常规的网络传输中，sendmsg并不特指零拷贝技术的实现，但如果结合特定选项（如Linux下的SCM_RIGHTS）和合适的上下文，也可以实现

* 综合来看，mmap和sendfile更常用于与磁盘I/O相关的零拷贝场景，而sendmsg则在特定的进程间通信和网络传输中起到一定的零拷贝效果。其中sendfile最为典型地体现了在文件传输到网络时的零拷贝技术应用。

## nio socket编写流程

客户端 到 buffer 到channel 到selector 到线程 开始执行
selector.open获取一个选择器
1.当客户端连接时，会通过serversocketchannel得到对应的socketchannel    
2.selector进行监听 select()方法（可使用阻塞或者非阻塞方法），返回有事件发生的通道的个数。
3.将得到的channel注册到selector
4.注册后得到一个selectionkey,会被selector管理，以集合的方式
5.四种事件 读事件 写事件 连接成功事件 新连接事件
6.获取selectionkey
7.通过key获取channel
7.通过channel完成业务的处理

# 33.索引问题

索引解决的问题
1.索引极大的减少了扫描行数
2.避免重排序和临时表
3.将随机io变成顺序io

select * from user order by age desc;
这条sql会将所有的行加载到内存之后，再按age排序生成一张临时表表
再将这张表排序后返回给客户端如果临时表大于tmp_table_size的值（默认16M）,
那么这张内存临时表会变成磁盘临时表，如果加了索引的话，
索引本身是有顺序的，所以从磁盘读取行数本身就是按照age排序好的
不用生成临时表和额外排序，提升了性能

## 什么时候sql的索引失效呢

1.当sql语句中索引列是函数或者表示式的一部分
即where条件后面跟的是一个计算过程或者函数调用

2.隐式类型转换
比如说表里存的是个string但是sql写的是个int就会触发隐式类型转换
就会调用cast函数，于是就触发了上一条规约

3.隐式编码转换
如果两张表编码不一致那么当一句sql涉及到这两张表时就会触发隐式的函数调用
转换编码集

因为使用order by导致的全表扫描，加了索引还是全表扫描了，因为select *导致了回表查询

## 什么是回表查询呢

我们都知道普通索引叶子节点存主键id，聚簇索引叶子节点存具体的行的值

我们如果使用聚簇索引查到索引就找相对的行的值

如果使用普通索引就会先找到主键id，然后再走一遍聚簇索引找到具体的记录

这样就走了两次索引查询，故而叫做回表查询

## 索引下推

将部分条件从server层推送到innodb引擎层，减少server层的io操作层，让innodb自己判断哪些数据需要索引，哪些数据不需要索引。

# 34.mysql事务

## 事物的四大特性

1.原子性：是一个不可分割的整体，要么全都执行，要么全不执行。执行出错事务回滚。
2.隔离性：同一时间，只允许一个事务请求同一组数据。不同事物彼此之间没有干扰。
3.一致性：事务开始前和开始后。数据库的完整性约束没有被破坏。
4.持久性：事务完成后落盘，不能回滚。

## 事务的并发问题

脏读：事务A读取了事务B的数据，事务B回滚，A读到了脏数据。
幻读:事务A修改表A，事务B向表A插入了一条数据，事务A修改完发现表A有一条记录还没有被修改。
不可重读：事务Ａ不断的读表Ａ，事务Ｂ不断的修改表Ａ。导致事务Ａ读取到的数据不一致。

## 四大隔离级别

１．读未提交。就是读到脏数据
２．读已提交。就是要等另一个事务提交完了，才能够读取。解决了脏读问题
３．可重读。保证了每次的读到的数据一致，不管其他事务是否已经提交。解决了不可重读问题
４．序列化。开启一个序列化事务，其他事务的对数据表的写操作都会挂起。

## 不同的隔离级别可以解决什么问题

快照隔离并不能解决写偏差,需要串行化才可以解决.
快照隔离避免了只读查询中的幻读,但是在读写事务中幻读就会导致棘手的写偏差问题.

## 串行化的实现

1.字面上的串行执行事务,在单个线程上按顺序一次只执行一个事务
2.2pc
3.乐观并发控制技术，例如 可串行化快照隔离

串行化执行小结
1.事务必须小而快,只要有一个慢就会拖慢所有事务处理
2.写入吞吐必须低到能在单个cpu上处理,如若不然,事务需要能划分至单个分区,且不需要跨分区协调
3.可以跨分区,但是得限制,尽量少用
4.如果事务需要访问的数据不在内存中,则中止事务,异步的将数据提取到内存中.
同时基础继续处理其他事务,然后在数据加载完毕时重新启动事务.

mysql
有行锁表锁页锁三种
innob只有行锁表锁两种。

行所=锁
Record Lock（记录锁）：锁住某一行记录
Gap Lock（间隙锁）：锁住一段左开右开的区间
Next-key Lock（临键锁）：锁住一段左开右闭的区间

隐式加锁
对于常见的 DML 语句（如 UPDATE、DELETE 和 INSERT ），InnoDB 会自动给相应的记录行加写锁
默认情况下对于普通 SELECT 语句，InnoDB 不会加任何锁，但是在 Serializable 隔离级别下会加行级读锁

显式加锁
SELECT * FROM table_name WHERE ... FOR UPDATE，加行级写锁
SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE，加行级读锁

加锁的基本单位是next-key lock
当查询的记录是存在的，Next-key Lock 会退化成记录锁
当查询的记录是不存在的，Next-key Lock 会退化成间隙锁

# 35.mybatis的缓存

## 1.一级缓存(一级缓存sqlsession)

1.同一个 SqlSession 对象， 在参数和 SQL 完全一样的情况先， 只执行一次 SQL 语句

2.在同一个 SqlSession 中, Mybatis 会把执行的方法和参数通过算法生成缓存的键值， 将键值和结果存放在一个 Map 中， 如果后续的键值一样，
则直接从 Map 中获取数据；

3.不同的 SqlSession 之间的缓存是相互隔离的；

4.用一个 SqlSession， 可以通过配置使得在查询前清空缓存；

5.任何的 UPDATE, INSERT, DELETE 语句都会清空缓存。

## 2.二级缓存(二级缓存mapper)

二级缓存是用来解决一级缓存不能跨会话共享的问题的，范围是namespace 级别的，可以被多个SqlSession
共享（只要是同一个接口里面的相同方法，都可以共享），生命周期和应用同步。如果你的MyBatis使用了二级缓存，并且你的Mapper和select语句也配置使用了二级缓存，那么在执行select查询的时候，MyBatis会先从二级缓存中取输入，其次才是一级缓存，即MyBatis查询数据的顺序是：二级缓存
—> 一级缓存 —> 数据库。缓存的清除策略也是lru。增删改都会刷新缓存，而且是namespace级别的。所以比较好的实践是将一个表的相关的sql放入同一个mapper里面，这样既方便管理，同时也不会让二级缓存影响其他表。

## 3.关于mapper和repository

1.相同点
两个都是注解在Dao上

2.不同
@Repository需要在Spring中配置扫描地址，然后生成Dao层的Bean才能被注入到Service层中。

@Mapper不需要配置扫描地址，通过xml里面的namespace里面的接口地址，生成了Bean后注入到Service层中。

# 36.mysql相关

## 1.mysql的执行流程

1.连接器：请求接收和权限验证
2.查询缓存：命中则直接返回结果
3.分析器：词法分析，语法分析
4.优化器：执行计划生成，索引选择
5.执行器：操作引擎，返回结果

### 相关问题

1.使用长连接过多会导致mysql内存暴涨，因为在mysql执行时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。

2.如果create table的时候不指定存储引擎会默认使用innodb

3.一个连接除了建立以外如果没有后续动作，那么就是空闲连接，mysql的空闲连接是8小时断开

解决方案：
1.定期断开连接，或者程序里面判断执行过一个占用内存的大查询后。断开连接。之后要查询再重连。

    2.如果你用的mysql 5.7之后的版本，可以在每次执行一个比较大的操作后初始化连接资源

### 查询缓存

当连接建立以后就可执行语句了，mysql拿到一个请求会先去查询缓存看看，之前是不是执行过这条语句。之前执行过的语句可能会以key-value的形式，被直接缓存在内存里。key的相应的查询语句value是查询的结果。

建议不要使用查询缓存
1.查询缓存失效非常的频繁，只要有对一个的更新，这个表上所有的缓存都会被清空。因此你可能费劲的把查询结果缓存了起来，还没使用就被一个更新全部清空了。

    2.由上一条推出，那些更新很少，或者基本不怎么更新的表比较适合使用查询缓存。
    你可以将参数 query_cache_type 设置成 DEMAND这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样。

    当然

# 37.jwt

第一部分我们称它为头部（header),第二部分我们称其为载荷（payload, 类似于飞机上承载的物品)，第三部分是签证（signature).
1.header:
{
'typ': 'JWT',
'alg': 'HS256'
}
加密方式base64
2.payload:
自己添加的一些信息
{

}
加密方式还是base64
3.signature
使用用户选定的加密算法加盐的方式进行生成

三段用.组合就是jwt.

# 38.关于自动装箱类型的测试

使用自动装箱类型:6500
使用基本类型:702

计算还是不要使用对象类型,性能差了9倍还多.恐怖

# 39.g1垃圾回收器

# 垃圾回收活动类型

1. Minor GC（年轻代垃圾回收）：
   Minor GC主要针对的是Java堆内存中的年轻代（Young Generation）区域。年轻代通常被分为Eden区、Survivor 0区和Survivor 1区。
   当年轻代空间不足时，会触发Minor GC来清理不再使用的对象，并将存活的对象移动到另一个幸存者区或者晋升到老年代（Old
   Generation）。
   Minor GC相对频繁且速度较快，因为它处理的数据量相对较小。
2. Major GC（老年代垃圾回收）/ Full GC（完整垃圾回收）：
   Major GC是指对老年代进行的垃圾回收操作。当老年代空间不足或需要进行空间分配担保等情况下，JVM会执行Major GC以回收老年代中的废弃对象。
   Full GC则更加彻底，它不仅包括了对老年代的回收，还包括年轻代、方法区（如元空间或者永久代）、以及所有全局共享的Java对象的回收。
   Major GC和Full GC相比Minor GC更为耗时和影响性能，因为它们涉及的对象数量更多，执行过程复杂度更高。
3. Mixed GC（混合垃圾回收）：
   在某些垃圾回收器（如G1垃圾回收器）中，存在一种称为混合垃圾回收的操作，它同时回收年轻代和部分老年代。
   G1垃圾回收器的设计目标是尽可能地避免全堆扫描，通过将堆划分为多个大小相等的区域，并动态跟踪各个区域的价值密度，从而决定哪些区域优先进行回收，这种策略使得Mixed
   GC既能回收年轻代，也能选择性地回收部分老年代区域，以达到更优的吞吐量和暂停时间目标。

g1将整个内存划分成了一个个region，region有四种类型

* -XX：G1HeapRegionSize 设置region的大小，大小范围：1-32M，数量上限：2048个

1. eden 新生代
2. Survivor 幸存代
3. Humongous 大对象
    * 只要超过region的一半就会被划分为大对象
4. old 老年代
5. 超过region大小的超级大对象将被存放在连续的Humongous块里

G1垃圾收集算法主要应用在多CPU大内存的服务中，在满足高吞吐量的同时，尽可能的满足垃圾回收时的暂停时间，该设计主要针对如下应用场景：
重要的几个点
1.垃圾回收线程和应用线程并发执行。（说明垃圾回收还是会影响应用的运行）
2.空闲内存压缩时避免冗长的暂停时间
3.应用需要更多可预测的GC暂停时间
4.不希望牺牲太多的吞吐性能

## G1的几个概念：

1. Region：G1收集器所划分的内存区域（划分内存的基本单位）
2. SATB：Snapshot-At-TheBeginning，它是通过Root Tracing得到的，GC开始时候存活对象的快照
3. RSet：记录了其他Region中的对象，引用本Region中对象的关系，属于points-into结构（谁引用了我的对象
   这其实是一个类似哈希的结构，key是别的region的起始地址，value是一个集合，里面存储的元素是卡表的索引号
4. 每个region哟i两个tams指针，把region中的一部分空间划分出来用于并发回收过程中的新对象分配。
5. Card Table，每个region有一个card table，当一个对象被修改时，会将该对象的Card标记为1，当Card标记为1时，会触发扫描

G1中的Young GC过程，和以往的是一样的：
新对象进入Eden区
存活对象拷贝到Survivor区
存活时间达到年龄阈值时，对象晋升到Old区

但是G1中没有Full GC，取而代之的是Mixed GC：
它不是Full GC，所以触发Mixed GC时回收的是所有的Young区和部分Old区的垃圾

G1里还有一个概念叫全局并发标记（global concurrent marking），和CMS的并发标记是类似的：
1.Initial marking phase：标记GC Root，STW
2.Root region scanning phase：根区扫描
3.Concurrent marking phase：并发标记存活对象
4.Remark phase：重新标记，STW
Cleanup phase：部分STW

## g1的步骤

1. 初始标记
   仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS
   指针的值，让下一阶段用户线程并发运行时，能正确地在可用的Region中分配新对象。这个阶段需要
   停顿线程，但耗时很短，而且是借用进行Minor GC的时候同步完成的，所以G1收集器在这个阶段实际
   并没有额外的停顿。
2. 并发标记
   从GC Root开始对堆中对象进行可达性分析，递归扫描整个堆
   里的对象图，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行。当对象图扫描完成以
   后，还要重新处理SATB记录下的在并发时有引用变动的对象。
3. 最终标记
   对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留
   下来的最后那少量的SATB记录。
4. 筛选回收
   负责更新Region的统计数据，对各个Region的回
   收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划，可以自由选择任意多个Region
   构成回收集，然后把决定回收的那一部分Region的存活对象复制到空的Region中，再清理掉整个旧
   Region的全部空间。这里的操作涉及存活对象的移动，是必须暂停用户线程，由多条收集器线程并行

## G1相关调优参数：

设置堆占有率达到这个参数值则触发global concurrent marking，默认值为45%：
-XX:InitiatingHeapOccupancyPercent
设置在global concurrent marking结束之后，可以知道Region里有多少空间要被回收，在每次YGC之后和再次发生Mixed
GC之前，会检查垃圾占比是否达到此参数的值，只有达到了，下次才会发生Mixed GC：
-XX:G1HeapWastePercent
设置Old区的Region被回收时的存活对象占比：
-XX:G1MixedGCLiveThresholdPercent
设置一次global concurrent marking之后，最多执行Mixed GC的次数：
-XX:G1MixedGCCountTarget
设置一次Mixed GC中能被选入CSet的最多Old区的Region数量：
-XX:G1OldCSetRegionThresholdPercent

## 其他参数：

-XX:+UseG1GC //开启G1收集器
-XX:G1HeapRegionSize=n //设置Region的大小，大小范围：1-32M，数量上限：2048个
-XX:MaxGCPauseMillis=200 //垃圾回收停顿时间设置最大停顿时间
-XX:G1NewSizePercent //设置Young区大小
-XX:G1MaxNewSizePercent //设置Young区最大占整个Java Heap的大小，默认值为60%
-XX:G1ReservePercent=10 //保留防止to space溢出
-XX:ParallelGCThreads=n //设置SWT线程数
-XX:ConcGCThreads=n //并发线程数=1/4*并行

## 注意事项：

年轻代大小：避免使用-Xmn、-XX:NewRatio等显式设置Young区大小，会覆盖暂停时间目标
暂停时间目标：暂停时间不要太严苛，其吞吐量目标是90%的应用程序时间和10%的垃圾回收时间，太严苛会直接影响到吞吐量

nohup java -XX:+UseG1GC -Xmx1024M -Xms1024M -XX:MaxMetaspaceSize=256M -XX:MetaspaceSize=256M -jar dental-customer.jar >
customer.out 2>&1 &

nohup java -XX:+UseG1GC -Xmx512M -Xms512M -XX:MaxMetaspaceSize=256M -XX:MetaspaceSize=256M -jar dental-report.jar >
report.out 2>&1 &

nohup java -XX:+UseG1GC -Xmx1024M -Xms1024M -XX:MaxMetaspaceSize=256M -XX:MetaspaceSize=256M -jar dental-search.jar >
search.out 2>&1 &

nohup java -XX:+UseG1GC -Xmx1024M -Xms1024M -XX:MaxMetaspaceSize=256M -XX:MetaspaceSize=256M -jar dental-service.jar >
service.out 2>&1 &

nohup java -XX:+UseG1GC -Xmx1024M -Xms1024M -XX:MaxMetaspaceSize=256M -XX:MetaspaceSize=256M -jar dental-web-admin.jar >
admin.out 2>&1 &

## 三色标记

是可达性分析的基础方法之一。

1. 白色：表示对象尚未被垃圾收集器访问过。在垃圾回收开始阶段，所有活跃的对象都会被初始化为白色。如果在后续的标记过程中，一个对象始终保持白色，则说明没有从根对象或其他已标记的对象通过引用链到达这个对象，因此它被认为是不可达的，即垃圾对象。
2. 灰色：些对象已经被垃圾收集器访问过，并且至少有一个指向其他对象的引用还未被扫描。这意味着灰色对象本身是可达的，但其引用的对象可能还待进一步判断是否可达。垃圾收集器会从根对象集合出发，将它们标记为灰色，并将其引用队列化等待后续处理。
3. 黑色：黑色对象不仅已被垃圾收集器访问过，而且其所有指向其他对象的引用也已被扫描过，并且这些引用的目标对象也都已经被正确地标记了。黑色对象本身及其引用的所有可达对象都是安全的，不会在这次垃圾回收中被清除。

## g1日志

里面会有eden，survivor,heap，metaspace大小以及使用量。可以判断那一块内存不足
(full 1),1会正常自增，出现多少次说明有多少次full gc。

# 40.双检锁的一些问题

外层判空是为了解决已经实例化对象后调用方法的性能问题（访问修饰锁的方法有较大开销） 中间加锁的方法是为了保证同一时间只有一个线程去实例化对象
内层判空是为了解决非原子操作可能因指令重排序导致的问题

# 41.传值还是传引用

对象传引用,基础类型传值

# 42.mq相关

优点:解耦,异步,削峰

## 解耦

一个系统向多个系统发起调用,每个系统需要一段代码,添加或者删除一个系统都需要修改代码.
如果加入mq那么发送方就不需要修改.

总结：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型，系统就跟其它系统彻底解耦了。

## 异步

比如订单系统,那么下单的那一下必须是同步的,算积分,送礼品等系统则可以异步去处理.降低了响应所需的时间.

## 削峰

就是降低流量对系统的压力,将请求暂时存储在mq中,然后后端服务器均速消费.

缺点:

## 降低系统可用性

解决方案.分布式集群模式
对于kafka来说topic是业务分区,partition是存储的逻辑分区,broker是物理分区(节点)
,topic有多个partition,多个partition分散存储在broker上,partition的同步副本会存储在
不同broker上.

## 系统复杂度提高

重复消费怎么办,幂等保持.全局唯一id.

## 消息丢失怎么办(kafka)

1.消费端丢失
消费到一半,服务挂了,或者消费错误,但是自动提交了当期消息的offset.
(处理方法关闭自动提交).

2.kafka丢数据
就是当leader broker的挂掉,但follower broker的数据有部分没有完全同步.那么当
当前follower成为leader的时候就会丢失一部分数据.

给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower
还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
在 producer 端设置 acks=all ：这个是要求每条数据，必须是写入所有 replica 之后，才能认为是写成功了。
在 producer 端设置 retries=MAX （很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了。

这些参数保证leader不会丢失数据,但是最新版本使用raft的版本,应该不存在这种问题,因为raft保证节点半数以上数据不丢失.

3.生产者会不会弄丢数据
如果按照上述的思路设置了 acks=all ，一定不会丢，要求是，你的 leader 接收到消息，
所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。

## 如何保证消息的顺序

kafka在生产者写的时候可以指定一个key, 那么这个key相关的数据都会写到同一个partition当中.
partition是以写log的方式落盘的所以一定是有序的.

多线程消费的时候怎么保证顺序呢?
起多个内存的queue,相关消息hash到同一个queue里,然后多线程分别去处理内存queue即可.

## 一致性问题

即部分系统消费成功,部分消费失败.

## 消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？

1.有积压,一般就是consumer出问题了.做法先修复问题保证正常消费.然后不做消息处理,而是转发到提前准备的多个队列中,开多
consumer消费,消费完毕后,恢复原有架构即可.

## 如何基于kafka实现延时队列

1. 根据延时等级创建n个topic
2. 消费者消费到Java延时服务的delay queue中，当时间到达的时候在发送到真正的业务topic
3. 消费业务topic即可

# 43.linux下的五种io模型

## Blocking I/O：

阻塞 I/O

## Non-Blocking I/O：

非阻塞 I/O

## I/O Multiplexing：

I/O 多路复用

## Signal Blocking I/O：

信号驱动 I/O

## Asynchronous I/O：

异步 I/O

# 44.java类型擦除

```java

/**
 * 定义一个泛型类，其中
 * Type Parameter是T extends Number
 * Type Variable是T
 * Type Argument是Foo<Integer>里的Integer
 */
class Foo<T extends Number> {
}
```

## 缺陷

1. 泛型的类型参数<T>在编译时用于静态类型检查,但在运行时被擦除(被替换)为
   他们的上界(没有指定则变成object),所以运行时无法获取<T>的类型信息。
2. 所以我们无法通过反射API，在运行期获得Type Variable所代表的类型。

# 45.spring事务

在Transactional中,数据库连接存储在一个ThreadLocal缓存当中,所以每一个线程有自己独立的连接,
当主线程,或者主线程中的一个异步线程,发生异常的时候,无法做到全部回滚,因为他们使用的是不同的数据库
连接

## 结局方案

## Spring事务失效的场景还有几点如下:

1. 非public修饰
2. final修饰也会失效, 动态代理需要重写方法才能生效事务, final修饰则无法重写
3. static修饰也会失效
4. 吞了异常, catch住没有抛给spring
5. 抛了错误的异常, catch住手动抛Exception则不会回滚, 因为spring事务只会处理RuntimeException和Error

# 46.Feign 第一次调用为什么会很慢

## Ribbon

Feign是靠Ribbon做负载的，而Ribbon需要拿到注册中心的服务列表，
将服务进行负载缓存到本地，然后FeignClient客户端在进行调用，大概就是这么一个过程。

## RibbonClientConfiguration

RibbonClientConfiguration类中通过LoadBalancer，我们知道ribbon是靠LoadBalancer做负载的
无非就是ILoadBalancer接口的方法，依次是添加新的服务、在负载均衡里选择一个服务、markServerDown服务下线、获取服务列表、获取存活的服务器、获取所有服务器（包括健康和不健康的）
![img_6.png](data%2Fimg_6.png)

## ZoneAwareLoadBalancer

loadBalancer默认的是ZoneAwareLoadBalancer负载均衡器，
通过继承父类DynamicServerListLoadBalancer的restOfInit方法，
里面比较重要的两个方法，enableAndInitLearnNewServersFeature和updateListOfServers方法

## Ribbon负载均衡策略

1. RoundRobinRule（轮询策略，按照服务顺序依次循环调用）

2. WeightedResponseTimeRule（权重比策略，优先选择权重比高的服务，也就是服务响应时间比较短的，响应时间越长权重比越低）

3. RandomRule（随机策略，服务提供者列表随机选择一个服务）

4. BestAvailableRule（最小连接数策略，获取服务列表中连接数最小的服务实例）

5. RetryRule（重试策略，重试获取已经失效的服务，指定时间没有获取到返回NULL）

6. AvailabilityFilteringRule（可用性敏感策略，过滤非健康服务实例，选择lianji）

7. ZoneAvoidanceRule（区域敏感策略）。
   具体来说，ZoneAvoidanceRule 在选择服务实例时，会考虑实例所属的区域信息，并尽量选择位于不同区域的实例。这样，在某个区域发生故障或者网络问题时，仍然能够保证服务的可用性，因为其他区域的实例仍然可用。

## Ribbon-eager-load（饥饿加载）模式

默认是懒加载，第一次调用的时候会将feign客户端进行负载，然后进行调用，第一次调用时间就会长一点

可以通过饥饿加载解决，配置如下

```yaml
ribbon:
  nacos:
    enabled: true # 开启naocos轮询
  eager-load:
    enabled: true  # 开启Ribbon的饥饿加载模式(防止第一次请求超时的问题)
    clients: Lxlxxx-system2 # 指定需要开启的服务(需要开启Ribbon的饥饿加载模式)
    ReadTimeout: 10000
    ConnectTimeout: 10000
    MaxAutoRetries: 0
    MaxAutoRetriesNextServer: 1
    OkToRetryOnAllOperations: false
```

# 47.B+树

只有叶子节点才存储数据，其他节点存储索引，每一页16kb，意味这比b树能存储更多的数据，
也就是说树的层数要少。那么查询效率就高。

## 层数估算

求B+树的高度这个。非叶子节点中存储的是索引字段+页指针，索引字段是long 类型就是 8
字节，页指针可能是4或者8字节，暂且当作8字节，那么一个索引页能存储的索引字段的数量是2^14/2^4 = 2^10个字段
（因为一个数据页还有一些元信息，真正能用来存储数据的并不没有16K，这里为了便于计算只是一个估计）。
一个数据页能存储的数据行数约等于16条。那么可以得到一个式子：
(2^10)^(h-1)*2^4=5000w，5000w约等于2^26，于是可以计算出h就是3~4之间

# 48.class.forName和classLoader的区别

## 类加载机制

1. 双亲委派：一个类加载加载类的时候，自己不能直接加载，就向上
   寻找父加载器，知道没上级为止。

2. 破坏双亲委派，同名类只能加载一个的问题
   自己定义一个类加载器，重写loadClass方法
    * 类库版本隔离：
      在一个Tomcat服务器上可能会部署多个Web应用，而这些应用可能依赖于不同版本的相同第三方库。如果遵循标准的双亲委派机制，那么同一个类库只能存在一份，无法满足不同应用对不同版本类库的需求。通过打破该机制，每个Web应用可以拥有独立的类加载器，加载各自所需的特定版本类库，从而实现类库的版本隔离。
    * 热部署和更新：
      Tomcat为了支持Web应用的热部署（无需重启服务器即可部署或更新应用），需要具备加载新版本类文件的能力。使用自定义类加载器结构可以实现在不干扰其他已部署应用的情况下，只重新加载当前应用的类资源。
    * 安全性和隔离性增强：
      为了避免不同Web应用之间的类相互影响，确保它们之间保持一定的边界，Tomcat设计了每个Web应用都有自己的WebAppClassLoader，它会优先从当前应用的目录下加载类，而不是委托给父加载器，这样就可以防止恶意代码或者错误配置的应用影响到服务器上的其他应用。
      综上所述，Tomcat通过破坏双亲委派机制，实现了类加载的个性化需求，增强了Web应用的部署灵活性、安全性和可维护性。

## java1.8的加载器

1. 启动类加载器
2. 扩展类加载器
3. 应用类加载器
4. 自定义加载器

## 类的生命周期

1. 加载
   通过全类名来获取该class的二进制字节流。
   将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。
   在java堆中生成一个代表这个类的java.lang.class对象，作为方法去这些数据的访问入口。
2. 链接（校验，准备，解析）
    * 验证阶段
        1. 文件格式验证（是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理）
        2. 元数据验证（对字节码描述的信息进行语意分析，以保证其描述的信息符合Java语言规范要求）
        3. 字节码验证（保证被校验类的方法在运行时不会做出危害虚拟机安全的行为）
        4. 符号引用验证（虚拟机将符号引用转化为直接引用时，解析阶段中发生）
    * 准备阶段
        1. 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段。将对象初始化为“零”值
    * 解析阶段
        1. 解析阶段时虚拟机将常量池内的符号引用替换为直接引用的过程。
           字符串常量池：堆上，默认class文件的静态常量池
           v运行时常量池：在方法区，属于元空间
3. 初始化
    * 初始化阶段时加载过程的最后一步，而这一阶段也是真正意义上开始执行类中定义的Java程序代码。
4. 使用
5. 卸载

## 区别

class.forName会自动初始化，执行静态代码
如果调用
public static Class<?> forName(String name, boolean initialize,
ClassLoader loader)

这个重载方法，则不初始化
classLoader不初始化。

## 服务注册

1. 服务注册：
   当一个服务启动后，它会将自己的网络地址和其他元数据信息注册到服务注册中心。这个过程通常在服务启动初始化阶段完成。
2. 服务发现：
   当一个服务需要调用其他服务时，它会向服务注册中心查询目标服务的网络地址，然后再发起调用。
3. 服务续约：
   为了让服务注册中心知道服务是否还在正常运行，服务会定期向服务注册中心发送心跳。如果服务注册中心在一定时间内没有收到某个服务的心跳，它会认为该服务已经宕机，并将其从注册表中移除。
4. 服务下线：
   当一个服务关闭时，它会向服务注册中心发送下线请求，服务注册中心会将该服务从注册表中移除。

# 49.springboot自动装配原理

1. SpringBoot 定义了一套接口规范，这套规范规定：SpringBoot 在启动时会扫描外部引用 jar
   包中的META-INF/spring.factories文件，将文件中配置的类型信息加载到 Spring 容器（此处涉及到 JVM 类加载机制与 Spring
   的容器知识），并执行类中定义的各种操作。对于外部 jar 来说，只需要按照 SpringBoot 定义的标准，就能将自己的功能装置进
   SpringBoot。

## SpringBoot 是如何实现自动装配的？

核心注解：@EnableAutoConfiguration
自动装配核心功能的实现实际是通过 AutoConfigurationImportSelector类。
ImportSelector接口，也就实现了这个接口中的 selectImports方法，该方法主要用于获取所有符合条件的类的全限定类名，这些类需要被加载到
IoC 容器中。

1. 判断自动装配开关是否打开。默认spring.boot.enableautoconfiguration=true，可在 application.properties 或 application.yml
   中设置
2. 用于获取EnableAutoConfiguration注解中的 exclude 和 excludeName(要主动排除那些类)。
3. 获取需要自动装配的所有配置类，读取META-INF/spring.factories
4. 到这里可能面试官会问你:“spring.factories中这么多配置，每次启动都要全部加载么？”。
   很明显，这是不现实的。我们 debug 到后面你会发现，configurations 的值变小了。
   @ConditionalOnXXX 系列注解中的条件都满足才会被加载到 Spring 容器中。

## 如何实现一个 Starter

1. 创建一个Maven项目，添加依赖
2. 引入 Spring Boot Stater相关依赖
3. 变相相关的@Configuration类
4. 在resources包下创建META-INF/spring.factories文件，写入全类名。]()

# 50. SpringBoot 的启动流程

ScheduledExecutorService 是 Java 并发库 java.util.concurrent 中的一个接口，它扩展了 ExecutorService
接口，提供了一种执行周期性任务或延迟任务的能力。通过使用 ScheduledExecutorService，开发者能够调度任务在未来的某个时间点开始执行一次或者定期重复执行。
主要方法：

* schedule(Callable<V> callable, long delay, TimeUnit unit)：
  安排一个 Callable 任务在给定的延迟后执行，返回一个 ScheduledFuture 表示将来结果。
* schedule(Runnable command, long delay, TimeUnit unit)：
  安排一个 Runnable 任务在给定的延迟后执行，返回一个 ScheduledFuture，可用于取消任务或检查其完成状态。
* scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit)：
  安排一个 Runnable 任务，在首次执行前等待初始延迟，然后以固定的周期连续执行。每次任务执行之间的时间间隔是恒定的，不受任务实际执行所需时间的影响。
* scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit)：
  类似于 scheduleAtFixedRate，但不同之处在于下一次执行会在上一次执行结束后加上指定的延迟才开始，这意味着两次执行之间的实际时间间隔至少是给定的延迟值，如果任务执行耗时较长，则会更长。
  实例化方式： 通常，我们可以使用 Executors 工具类来创建一个 ScheduledExecutorService 的实现，如
  ScheduledThreadPoolExecutor：

# 51. 线程的状态

new
runnable
blocked
waiting
timed_waiting
terminated

# 52.java的内存屏障

load load
store store
load store
store load当前处理器写缓冲区中的数据全部刷新到内存中。

# 53.反射

1. 反射是动态运行时的机制，可以获取类的信息，包括类的成员变量、方法、构造器、注解等信息。

## 原理

在类加载时候，jvm会读取。class文件，并对其进行解析，生成classInfo，并存储在方法区中。

# 54.协程

协程是并发编程的一种方式，它允许程序员在一个线程中执行多个任务，而不需要创建多个线程。协程通过使用栈和上下文切换来实现，从而实现并发执行多个任务。

go语言是有栈协程实现。

# 55.用户态和内核态

用户态和内核态是计算机操作系统中的一种核心概念，用来描述CPU在执行程序时的两种不同特权级别：

## 用户态（User Mode）：

当进程或线程运行在其自己的地址空间内，并且只能访问分配给它的资源时，它处于用户态。用户态下的代码权限较低，不能直接访问硬件设备、内存管理系统中的某些区域以及操作系统的核心数据结构。
用户态程序通常包括普通应用程序，它们受到严格的限制以保护系统的安全性和稳定性。例如，它们不能直接读写物理内存、发起系统中断或者执行系统级别的操作。

## 内核态（Kernel Mode 或 Supervisor Mode）：

内核态是指当CPU执行操作系统内核代码时的状态，此时处理器拥有最高权限，可以不受限制地访问计算机的所有资源，包括所有的内存、I/O设备以及其他硬件组件。
操作系统内核及其驱动程序在内核态下运行，负责处理如进程调度、内存管理、设备驱动控制、系统调用服务等关键任务。
从用户态切换到内核态通常发生在以下几种情况：
系统调用：用户态程序通过特定指令发起对内核服务的请求，比如读取文件、创建新进程等，这时CPU会切换到内核态来执行这些请求。
异常或中断：当硬件设备需要操作系统干预时（如键盘输入、网络数据到达），会产生中断信号，CPU响应中断后会进入内核态执行相应的处理程序。

## 用户态和内核态切换

操作系统在启动的时候会使用mmu机制，对物理内存进行虚拟化映射。
用户态程序有自己的虚拟地址空间，这个空间被限制在某个范围之内，不允许直接访问内核代码和数据所在的地址区域。
内核拥有独立且全部的虚拟地址空间，其中包含了内核代码、内核数据结构以及所有硬件设备的驱动程序等。

# 56. CompleteableFuture

1. 异常处理：需要调用exceptionally()方法处理。
2. 避免阻塞：使用thenApply，thenAccept，thenRun等方法处理。
   thenApply接受一个函数作为参数，将CompletableFuture的结果作为输入，并返回一个新的值。
   thenAccept接受一个消费者作为参数，将CompletableFuture的结果作为输入，并不返回任何值。
   thenRun接受一个Runnable作为参数，在CompletableFuture完成时执行，不接受任何参数，也不返回任何值。
3. 链式调用：使用thenCompose，thenCombine，thenApplyAsync等方法处理。
4. 资源管理：使用了数据库链接，io操作等要及时的关闭。
5. 执行策略：指定线程池来执行任务。

# 57.io多路复用

## select

## poll

## epoll

## 边缘触发，水平触发

# 58.cpu中断

## 硬中断（Hardware Interrupts）

硬中断通常由外部设备触发，比如网卡接收到网络数据包、磁盘完成IO操作或者键盘被按下等。这些事件会通过中断控制器发送一个信号到CPU，通知CPU暂停当前的任务并转而去处理这个事件。硬中断的特点包括：
中断号通常由中断控制器提供，CPU响应中断时会查询中断描述符表（IDT）来找到对应的中断服务例程（ISR）进行处理。
处理硬中断的程序必须迅速完成其核心功能，也就是所谓的“上半部”工作，例如把数据从硬件缓冲区复制到内核空间，以免阻塞其他中断或影响系统的响应速度。
对于复杂的后续处理，硬中断可能触发一个软中断或工作队列，让这些操作在较低优先级下异步完成，即所谓的“下半部”工作。

## 软中断（Software Interrupts）

软中断是由正在执行的指令显式生成的，而不是来自外部硬件。它们主要用于内核服务，如系统调用、定时器中断、tasklet（轻量级下半部任务）以及工作队列等。特点包括：
软中断可以通过特定的指令或系统调用主动触发，不需要中断控制器参与。
软中断是可以调度的，也就是说它们可以在进程上下文而非中断上下文中执行，这意味着它们可以睡眠并等待资源。
软中断主要用于处理那些不紧急或者不适合在硬中断上下文中执行的延后任务，例如处理硬中断中的下半部工作，或者定期执行的后台任务。
总结来说，硬中断主要处理来自硬件的突发性事件，保证快速响应；软中断则作为内核内部的一种协同机制，处理更为复杂的同步和异步操作。两者相互配合，共同构成了现代操作系统中高效、灵活的中断处理体系结构。